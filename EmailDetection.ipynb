{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4767d74-9533-4f19-85a6-696c795414df",
   "metadata": {},
   "source": [
    "# Import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d04b5430-8877-459a-977b-a613f66a2745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sahub\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import spacy\n",
    "from afinn import Afinn\n",
    "import pickle\n",
    "seed=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a34c8a-fdbb-40f9-9707-276215118f54",
   "metadata": {},
   "source": [
    "# Text exploration and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "91790ba1-0bb8-4dee-be30-3e6e447ec6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails= pd.read_csv(r\"email_class.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43063931-97c2-4ba5-9c09-f630e729d648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "decccf27-ca42-4d73-9ae2-1eea74f35790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  5572 non-null   object\n",
      " 1   Message   5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "emails.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd9d6e9b-8ad1-4465-bbfe-68318b0526f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duplicated values\n",
    "emails.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "110df17d-9aba-4bdc-bc2c-584287052079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "emails=emails.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f246f05-6140-48e7-8e62-81874fcf65cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5157 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  5157 non-null   object\n",
      " 1   Message   5157 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 120.9+ KB\n"
     ]
    }
   ],
   "source": [
    "emails.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a01e2-9e1a-4e3a-b17c-4a698357e725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8a35fa25-2471-498a-bda9-4dd1e5a6abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to preprocess the text\n",
    "def preprocess_text(row):\n",
    "    # remove white space\n",
    "    row=row.strip()\n",
    "    # Lowercase\n",
    "    row=row.lower()\n",
    "    #remove punctuation\n",
    "    row= ''.join([char for char in row if char not in string.punctuation])\n",
    "    #tokeization\n",
    "    tokens=word_tokenize(row)\n",
    "    # create an instance of english stopwords\n",
    "    stopwordss=stopwords.words('english')\n",
    "    #remove stopwords\n",
    "    tokens=[x for x in tokens if not x in stopwordss]\n",
    "    # create an instance of stem\n",
    "    ps=PorterStemmer()\n",
    "    # stem the tokens\n",
    "    stems=[ps.stem(x) for x in tokens]\n",
    "    return \" \".join(stems)\n",
    "\n",
    "# apply the function to all the rows\n",
    "emails['preprocessed_Message']=emails['Message'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d4e9b030-d8f4-475e-bd3d-e41263e79e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>preprocessed_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "\n",
       "                                preprocessed_Message  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview of data\n",
    "emails.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ad880872-1e12-4d1e-adba-e1404e6f3751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5157, 5000)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crate the tfidf vectorizer\n",
    "tfidf=TfidfVectorizer(max_features=5000)\n",
    "# fit the data and store it into X\n",
    "x=tfidf.fit_transform(emails['preprocessed_Message'])\n",
    "# output \n",
    "y=emails['Category']\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2840654c-d3ac-4069-bfa5-8dd9dd366150",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tfidf.pkl\",'wb') as file:\n",
    "    pickle.dump(tfidf,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5e3c2-ac6e-423a-b4cd-7e2ccc9db45f",
   "metadata": {},
   "source": [
    "# Naive Bayes- Text classification model Building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6b07edb9-35c6-43b2-9248-2a64b1aa96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "train_x,test_x, train_y, test_y= train_test_split(x,y,test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "abe54177-ca5e-4518-80b5-3e2b427409e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params; {'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter-tuning\n",
    "param_grid={'alpha':[0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "\n",
    "# Gridsearch\n",
    "nb=MultinomialNB()\n",
    "grid_cv=GridSearchCV(nb,param_grid,cv=5)\n",
    "grid_cv.fit(train_x,train_y)\n",
    "print(\"best params;\",grid_cv.best_params_)\n",
    "\n",
    "# final model\n",
    "nb_model=grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb8fbc-a2db-4fde-a45c-c846ecc18c40",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8ff8c7db-0e3c-4d7e-9ad6-a417cc71a4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Metrics  Train_data  Test_data\n",
      "0   Accuracy    0.995012   0.980620\n",
      "1  Precision    0.995005   0.980370\n",
      "2     Recall    0.995012   0.980620\n",
      "3   F1_score    0.994983   0.980404\n"
     ]
    }
   ],
   "source": [
    "# predictions for train and test data\n",
    "train_pred=nb_model.predict(train_x)\n",
    "test_pred=nb_model.predict(test_x)\n",
    "\n",
    "# function for evaluation\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred,average='weighted')\n",
    "    recall = recall_score(y_true, y_pred,average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred,average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "train_metrics = evaluate_model(train_y, train_pred)\n",
    "test_metrics = evaluate_model(test_y, test_pred)\n",
    "\n",
    "metric=['Accuracy','Precision','Recall','F1_score']\n",
    "\n",
    "# Compile results into a DataFrame\n",
    "results = pd.DataFrame({'Metrics':['Accuracy','Precision','Recall','F1_score'],\n",
    "    'Train_data': [train_metrics[0],train_metrics[1],train_metrics[2],train_metrics[3]],\n",
    "    'Test_data': [test_metrics[0],test_metrics[1],test_metrics[2],test_metrics[3]]})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2e849f89-4914-4c5e-b09b-67e774da99ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_Label</th>\n",
       "      <th>Predicted_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     True_Label Predicted_Label\n",
       "5320        ham             ham\n",
       "3462        ham             ham\n",
       "1711        ham             ham\n",
       "2735        ham             ham\n",
       "2877        ham             ham"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'True_Label': train_y,  # The true labels from the training set\n",
    "    'Predicted_Label': train_pred  # The predicted labels from the model\n",
    "})\n",
    "results_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e2c3becf-c8b6-400e-adf8-32d566863b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "with open('NBModel.pkl','wb') as file:\n",
    "    pickle.dump(nb_model,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196bd3c-44a7-4ebc-94a7-559796b0da6d",
   "metadata": {},
   "source": [
    "# Sentiment Analysis:\n",
    "- Evaluate the sentiment of the text using four different methods: AFINN, VADER, NRC (National Research Council Emotion Lexicon), and TextBlob."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0efeb-3e85-4897-b852-9e6108f08447",
   "metadata": {},
   "source": [
    "## Afinn\n",
    "- Lexicon-based: AFINN uses a pre-built list of words where each word has been assigned a sentiment score between -5 (most negative) and +5 (most positive).\n",
    "- It is straightforward: The sentiment score for a sentence is the sum of the individual word scores. The overall sentiment is determined by summing the values of these words.\n",
    "- No handling of negation or context: AFINN does not take into account negations (e.g., “not good”) or more complex syntactic elements like context or sentence structure. So, \"not bad\" and \"bad\" would both get a similar negative score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0820972c-a396-4102-ac6a-299f55e17528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from afinn import Afinn\n",
    "\n",
    "nlp= spacy.load('en_core_web_sm')\n",
    "afinn=Afinn()\n",
    "def afinnAnalyzer(text):\n",
    "    sentence=nlp(text)\n",
    "    sent_score_pos = 0\n",
    "    sent_score_neg = 0\n",
    "    sent_score_neutral = 0\n",
    "    for token in sentence:\n",
    "        word = token.text\n",
    "        sent_score = afinn.score(word)\n",
    "            \n",
    "        if sent_score > 0:\n",
    "            sent_score_pos += sent_score\n",
    "        elif sent_score < 0:\n",
    "            sent_score_neg += sent_score\n",
    "        else:\n",
    "            sent_score_neutral += sent_score\n",
    "    sentiment= sent_score_pos+sent_score_neg+sent_score_neutral\n",
    "    if sentiment>0:\n",
    "        return 'positive'\n",
    "    elif sentiment<0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6bf3788d-ea53-41eb-b623-bf85a106f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments=pd.DataFrame()\n",
    "sentiments['Message']=emails['Message']\n",
    "sentiments['Afinn']=emails['Message'].apply(afinnAnalyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbe87f7-f28a-4955-9d1a-a062f2360f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d240734c-9d54-43fb-ae0b-8a1235d0d573",
   "metadata": {},
   "source": [
    "## vader Analysis\n",
    "\n",
    "- Lexicon-based but designed to handle social media text: VADER uses a lexicon where words are scored between -4 and +4\n",
    "- Negation: “not good” would be recognized and adjusted to reflect a more neutral sentiment, unlike AFINN.\n",
    "- Punctuation and intensity: VADER increases the sentiment weight for words in all caps (“AWESOME”) and words followed by exclamation marks (“great!!!”).\n",
    "#### VADER provides four types of scores\n",
    "- 'neg': The negative sentiment score (ranges between 0 and 1).\n",
    "- 'neu': The neutral sentiment score.\n",
    "- 'pos': The positive sentiment score.\n",
    "- 'compound': The overall sentiment score, which is a normalized value between -1 (most negative) and +1 (most positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2e9b54c7-794a-4f02-ac88-f2b4250179e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sahub\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1dd7d7af-9c56-4158-9f10-d08bf8526412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vaderAnalyzer(text):\n",
    "    vader_analyzer=SentimentIntensityAnalyzer()\n",
    "    sentencescore=vader_analyzer.polarity_scores(text)\n",
    "    if sentencescore['compound']>0:\n",
    "        return \"Positive\"\n",
    "    elif sentencescore['compound']<0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "sentiments['Vader']=emails['Message'].apply(vaderAnalyzer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19a2c429-1de6-4d9c-a612-4ae2620aceef",
   "metadata": {},
   "source": [
    "## NRC (National Research Council) \n",
    "\n",
    "- The NRC (National Research Council) Emotion Lexicon is a lexicon-based tool that assigns emotions and sentiments to words.\n",
    "- Emotions are Anger, Anticipation, Disgust, Fear, Joy, Sadness, Surprise, Trust and sentiment (positive or negative)\n",
    "- Unlike VADER, which directly calculates sentiment scores for entire sentences, NRC focuses on tagging individual words with emotions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "29865547-0702-4020-8617-9f9c16f480ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nrclex in c:\\users\\sahub\\appdata\\roaming\\python\\python311\\site-packages (3.0.0)\n",
      "Requirement already satisfied: textblob in c:\\users\\sahub\\appdata\\roaming\\python\\python311\\site-packages (from nrclex) (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob->nrclex) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob->nrclex) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sahub\\appdata\\roaming\\python\\python311\\site-packages (from nltk>=3.8->textblob->nrclex) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob->nrclex) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob->nrclex) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->textblob->nrclex) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nrclex\n",
    "from nrclex import NRCLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "34138da5-3a5d-4438-8242-deda5111bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrc_analyzer(text):\n",
    "    emotion = NRCLex(text)\n",
    "    return emotion.top_emotions[0][0]\n",
    "\n",
    "sentiments['nrc_emotions']=emails['Message'].apply(nrc_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d22a1796-3d68-4294-ac62-601a4bb76071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Afinn</th>\n",
       "      <th>Vader</th>\n",
       "      <th>nrc_emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5157 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Message     Afinn     Vader  \\\n",
       "0     Go until jurong point, crazy.. Available only ...  positive  Positive   \n",
       "1                         Ok lar... Joking wif u oni...   Neutral  Positive   \n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...  positive  Positive   \n",
       "3     U dun say so early hor... U c already then say...   Neutral   Neutral   \n",
       "4     Nah I don't think he goes to usf, he lives aro...   Neutral  Negative   \n",
       "...                                                 ...       ...       ...   \n",
       "5567  This is the 2nd time we have tried 2 contact u...  positive  Positive   \n",
       "5568               Will ü b going to esplanade fr home?   Neutral   Neutral   \n",
       "5569  Pity, * was in mood for that. So...any other s...  Negative  Negative   \n",
       "5570  The guy did some bitching but I acted like i'd...  positive  Positive   \n",
       "5571                         Rofl. Its true to its name  positive  Positive   \n",
       "\n",
       "     nrc_emotions  \n",
       "0           anger  \n",
       "1            fear  \n",
       "2        positive  \n",
       "3        negative  \n",
       "4            fear  \n",
       "...           ...  \n",
       "5567     positive  \n",
       "5568         fear  \n",
       "5569         fear  \n",
       "5570     positive  \n",
       "5571        trust  \n",
       "\n",
       "[5157 rows x 4 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4c6b545-48b2-4402-a7fb-6c9213aa1b0b",
   "metadata": {},
   "source": [
    "## TextBlob\n",
    "\n",
    "- TextBlob is a simple tool for basic sentiment analysis. It works well for detecting general sentiment and subjectivity in text but doesn't handle complex emotions or slang like VADER or NRC\n",
    "- Polarity ranges from -1 (very negative) to +1 (very positive). It Shows whether the message is positive or negative\n",
    "- Subjectivity ranges from 0 (very objective) to 1 (very subjective). It Shows how subjective the message is, whether the text is subjective or objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "91b7c2ff-e768-4683-aa18-67660a43f017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in c:\\users\\sahub\\appdata\\roaming\\python\\python311\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sahub\\appdata\\roaming\\python\\python311\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a63bc739-a1be-4f34-a3d8-de0f1666fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob_analyzer(text):\n",
    "    blob= TextBlob(text)\n",
    "    polarity=blob.sentiment.polarity\n",
    "    if polarity>0:\n",
    "        text='Positive'\n",
    "        return pd.Series([text,blob.sentiment.subjectivity])\n",
    "    elif polarity<0:\n",
    "        return pd.Series([\"Negative\",blob.sentiment.subjectivity])\n",
    "    else:\n",
    "        return pd.Series([\"Neutral\",blob.sentiment.subjectivity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "27189205-d1ca-48bd-b856-41f1378c35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments[['blob_sentiment', 'blob_Subjectivity']]=emails['Message'].apply(blob_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7eefe24e-0969-4dfa-98e3-63ae533301d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Afinn</th>\n",
       "      <th>Vader</th>\n",
       "      <th>nrc_emotions</th>\n",
       "      <th>blob_sentiment</th>\n",
       "      <th>blob_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>anger</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>fear</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>fear</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message     Afinn     Vader  \\\n",
       "0  Go until jurong point, crazy.. Available only ...  positive  Positive   \n",
       "1                      Ok lar... Joking wif u oni...   Neutral  Positive   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  positive  Positive   \n",
       "3  U dun say so early hor... U c already then say...   Neutral   Neutral   \n",
       "4  Nah I don't think he goes to usf, he lives aro...   Neutral  Negative   \n",
       "5  FreeMsg Hey there darling it's been 3 week's n...  positive  Positive   \n",
       "6  Even my brother is not like to speak with me. ...  positive  Negative   \n",
       "7  As per your request 'Melle Melle (Oru Minnamin...   Neutral  Positive   \n",
       "8  WINNER!! As a valued network customer you have...  positive  Positive   \n",
       "9  Had your mobile 11 months or more? U R entitle...  positive  Positive   \n",
       "\n",
       "   nrc_emotions blob_sentiment  blob_Subjectivity  \n",
       "0         anger       Positive           0.762500  \n",
       "1          fear       Positive           0.500000  \n",
       "2      positive       Positive           0.550000  \n",
       "3      negative       Positive           0.300000  \n",
       "4          fear        Neutral           0.000000  \n",
       "5      positive       Positive           0.233333  \n",
       "6      positive        Neutral           0.000000  \n",
       "7      negative        Neutral           0.000000  \n",
       "8      positive        Neutral           1.000000  \n",
       "9  anticipation       Positive           0.750000  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7837bf-6065-4b27-8e27-0ffb0a873a57",
   "metadata": {},
   "source": [
    "- For Social Media or Informal Text: VADER is often the best choice because it handles slang, punctuation, and emojis.\r",
    "- \n",
    "For Analyzing Emotions Beyond Sentiment: NRC is useful if you’re interested in emotional categories like joy, fear, anger, etc\n",
    "-  \r\n",
    "For Speed and Simplicity: AFINN is the fastest and simplest, making it good for basic tasks where precision isn’t crucia\n",
    "-  .\r\n",
    "For General Sentiment and Subjectivity: TextBlob is a well-rounded choice, especially if you also need to perform other NLP tasks, like part-of-speech tagging or noun phrase extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2303cd-a8b3-4787-b7d5-52be86d1ce55",
   "metadata": {},
   "source": [
    "### The best method for sentiment analysis in this context is VADER, as it effectively handles informal language, which is common in these emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0474de9b-7fa0-4250-a147-37b07c8f191a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d08e5d-f5ed-463b-bb4b-a8fef1c26e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8344316f-3e44-4557-a466-840de63b982d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13beb4b2-eb95-4c28-8126-dd53739ad66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf272875-7ae0-452c-811c-6c8858328b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70080a4-b643-4b3b-b893-1abca71e41b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50049b-541c-482c-a82b-3f8bb15315f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b14528-6c0d-4621-8b13-a861897f8547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842b411-4ac2-426f-bc07-0cf498412fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0860f8-8a92-40bf-aa71-d4e07ef5d752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833eb4f-f167-42b5-98c2-80ad4b86ea15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ce768-d64b-46f0-bee5-f52eea82db11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915d2f1-d76a-4d83-8613-f410514039d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd284ea8-67d9-4989-849d-9a608e119cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1221051-328b-4100-9a20-c5427592fdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87764de-c0e0-412d-8a49-580a3750d0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
